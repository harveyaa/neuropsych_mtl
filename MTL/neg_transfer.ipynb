{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from itertools import combinations\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = ''\n",
    "prefix = ''\n",
    "path_out = ''\n",
    "\n",
    "\n",
    "all_cases = ['SZ',\n",
    "            'ASD',\n",
    "            'BIP',\n",
    "            'DEL22q11_2',\n",
    "            'DUP22q11_2',\n",
    "            'DEL16p11_2',\n",
    "            'DUP16p11_2',\n",
    "            'DEL1q21_1',\n",
    "            'DUP1q21_1']\n",
    "\n",
    "logs = os.listdir(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Single Task Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading single task results...')\n",
    "singles = []\n",
    "single_results = []\n",
    "for case in all_cases:\n",
    "    for l in logs:\n",
    "        seen = l.split('.')[0].split('-')[2:]\n",
    "        if (case in seen) & (len(seen)==1):\n",
    "            single_results.append(pd.read_csv(os.path.join(args.log_dir,l),header=[0,1],index_col=0))\n",
    "            singles.append(case)\n",
    "            print(case)\n",
    "print('Done!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #####################\n",
    "    # LOAD PAIR RESULTS #\n",
    "    #####################\n",
    "    print('Loading paired task results...')\n",
    "    pairs = []\n",
    "    pair_results = []\n",
    "    for case1,case2 in combinations(singles,2):\n",
    "        for l in logs:\n",
    "            seen = l.split('.')[0].split('-')[2:]\n",
    "            if (case1 in seen) and (case2 in seen):\n",
    "                pair_results.append(pd.read_csv(os.path.join(args.log_dir,l),header=[0,1],index_col=0))\n",
    "                pairs.append((case1,case2))\n",
    "                print(f\"{case1} {case2}\")\n",
    "    print('Done!\\n')\n",
    "    \n",
    "    ################\n",
    "    # GET BASELINE #\n",
    "    ################\n",
    "    # Call baseline avg of best & final accuracy\n",
    "    baseline = 0.5*(pd.concat(single_results,axis=1).iloc[-1] + pd.concat(single_results,axis=1).max()).loc[:,'Accuracy/test']\n",
    "    print('Baseline\\n--------')\n",
    "    print(baseline,'\\n')\n",
    "\n",
    "    ##################\n",
    "    # EVALUATE PAIRS #\n",
    "    ##################\n",
    "    name_to_idx = dict(zip(singles,list(range(len(singles)))))\n",
    "    counts = np.zeros((len(singles),2))\n",
    "    vals = np.zeros((len(singles),len(singles)))\n",
    "\n",
    "    for pair, results in zip(pairs,pair_results):\n",
    "        case1 = pair[0]\n",
    "        case2 = pair[1]\n",
    "\n",
    "        # Increment seen\n",
    "        counts[name_to_idx[case1],1] += 1\n",
    "        counts[name_to_idx[case2],1] += 1\n",
    "\n",
    "        # Record vals\n",
    "        case1_val = (results.max().loc[case1].loc['Accuracy/test'] + results.iloc[-1].loc[case1].loc['Accuracy/test'])/2\n",
    "        case2_val = (results.max().loc[case2].loc['Accuracy/test'] + results.iloc[-1].loc[case2].loc['Accuracy/test'])/2\n",
    "\n",
    "        # vals[case1,case2] = performance of case1 w/ case2\n",
    "        vals[name_to_idx[case1],name_to_idx[case2]] = case1_val\n",
    "        vals[name_to_idx[case2],name_to_idx[case1]] = case2_val\n",
    "\n",
    "        # Increment beat    \n",
    "        if case1_val > baseline.loc[case1]:\n",
    "            counts[name_to_idx[case1],0] += 1\n",
    "        if case2_val > baseline.loc[case2]:\n",
    "            counts[name_to_idx[case2],0] += 1\n",
    "    \n",
    "    ####################\n",
    "    # SUMMARIZE COUNTS #\n",
    "    ####################\n",
    "    summary_counts = pd.DataFrame(counts,index=singles,columns=['n_beat','n_seen'])\n",
    "    summary_counts = summary_counts.append(summary_counts.sum().rename('Total'))\n",
    "    print('Counts\\n------')\n",
    "    print(summary_counts)\n",
    "    print()\n",
    "\n",
    "    # Save\n",
    "    filename = args.prefix + '-counts.csv' if args.prefix is not None else 'counts.csv'\n",
    "    summary_counts.to_csv(os.path.join(path_out, filename))\n",
    "\n",
    "    ##################\n",
    "    # SUMMARIZE VALS #\n",
    "    ##################\n",
    "    # Make diagonal the baseline\n",
    "    np.fill_diagonal(vals,baseline.values)\n",
    "    summary_vals = pd.DataFrame(vals,index=singles,columns=singles)\n",
    "    print('Values\\n------')\n",
    "    print(summary_vals)\n",
    "    print()\n",
    "\n",
    "    # Save\n",
    "    filename = args.prefix + '-vals.csv' if args.prefix is not None else 'vals.csv'\n",
    "    summary_vals.to_csv(os.path.join(path_out, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('fmri')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ea07d7e26f64274b859969024e9bc122a0aaa5b386426249452447396636cf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
